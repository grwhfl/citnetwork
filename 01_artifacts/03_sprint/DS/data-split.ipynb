{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport logging\nfrom tqdm.auto import tqdm\nimport warnings\nfrom typing import Union\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"markdown","source":"Logger","metadata":{}},{"cell_type":"code","source":"logger_ = logging.getLogger()\nlogger_.setLevel(1)\n\nch = logging.StreamHandler()\nch.setLevel(1)\n\nlogger_.addHandler(ch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(df):\n    use_cols = ['_id', 'title', 'fos', 'abstract', 'lang', 'url', 'venue', 'authors', 'year',\n                'volume', 'keywords', 'doi', 'references', 'n_citation']\n    df = df[use_cols]\n    df['authors'] = df['authors'].astype('str')\n    df['references'] = df['references'].astype('str')\n    df['keywords'] = df['keywords'].astype('str')\n    df = df.drop_duplicates(subset=['title', 'authors', 'year', 'keywords', 'references', 'abstract'], keep='last')\n    df['n_citation'].replace(np.nan, 0, inplace=True)\n    df = df[(df['year'] < 2023)]\n    df = df[(df['year'] > 1960) & (df['n_citation'] != 0)]\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunksize = 5e5\nsum = 0\ni = 1\nfilenames = ['../input/cndbv13/test1.json', '../input/cndbv13/test2.json', '../input/cndbv13/test3.json', '../input/cndbv13/test4.json', '../input/cndbv13/test5.json']\nfor filename in filenames:  \n    with pd.read_json(filename, lines=True, chunksize=chunksize) as reader:\n        for chunk in tqdm(reader):\n            df = process(chunk)\n            new_filename = f'data_{i}.parquet'\n            df.to_parquet(new_filename)\n            i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet('data_1.parquet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train/Test split","metadata":{}},{"cell_type":"markdown","source":"Принцип разделения: статьи до определенного года - треин, после - тест.\nТакой подход был выбран из-за следующих его преимуществ:\n1. простота реализации метода\n2. отстусвие коллизий, т.е пересечений в train/test\n3. используется весь датасет после пред процессинга\n\nДанный подход имел бы существенные недостатки, если бы паттерны написания статей и вектор исследований был бы существенно изменен. Такое действительно имеет место, но влиянием можно пренебречь, так как статьи до 1980-го года были исключены на этапе очистки данных.","metadata":{}},{"cell_type":"code","source":"split_cfg = {\n    'test_size': 0.15\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_most_suitable_year(test_size: float, \n                           data: pd.DataFrame,\n                           years: set) -> int:\n    \"Just walk through all years and choose the most appopriate\"\n    dataset_size = len(data)\n    year_desision, delta = -1, float('inf')\n    for year in tqdm(years):\n        cur_test_size = len(data[data.year > year])/ dataset_size\n        if abs(cur_test_size - test_size) < delta:\n            year_desision = year\n            delta = abs(cur_test_size - test_size)\n    return year_desision","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_split(data: pd.DataFrame) -> tuple:\n    uniq_years = df.year.unique()\n    board_year = get_most_suitable_year(split_cfg['test_size'],\n                                        data,\n                                        uniq_years)\n    train, test = data[data.year <  board_year], data[data.year >  board_year]\n    return (train, test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(df)\nassert len(train_data) > len(test_data)\nlogger_.info('Successfull data splitting')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save result to csv..","metadata":{}},{"cell_type":"code","source":"train_data.to_csv('/kaggle/working/train.csv')\ntest_data.to_csv('/kaggle/working/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}